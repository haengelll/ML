{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 피처명에서 10개만 추출: ['tBodyAcc-mean()-X', 'tBodyAcc-mean()-Y', 'tBodyAcc-mean()-Z', 'tBodyAcc-std()-X', 'tBodyAcc-std()-Y', 'tBodyAcc-std()-Z', 'tBodyAcc-mad()-X', 'tBodyAcc-mad()-Y', 'tBodyAcc-mad()-Z', 'tBodyAcc-max()-X']\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# features.txt 파일에는 피처 이름 index와 피처명이 공백으로 분리되어 있음. 이를 DataFrame으로 로드.\n",
    "feature_name_df = pd.read_csv('../ML/human_activity/features.txt',sep='\\s+', header=None,\n",
    "                             names=['column_index', 'column_name'])\n",
    "# feature_name_df\n",
    "# # 피처명 index를 제거하고, 피처명만 리스트 객체로 생성한 뒤 샘플로 10개만 추출\n",
    "feature_name = feature_name_df.iloc[:, 1].values.tolist()\n",
    "print('전체 피처명에서 10개만 추출:', feature_name[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column_index    42\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>column_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fBodyAcc-bandsEnergy()-1,16</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fBodyAcc-bandsEnergy()-1,24</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fBodyAcc-bandsEnergy()-1,8</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fBodyAcc-bandsEnergy()-17,24</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fBodyAcc-bandsEnergy()-17,32</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              column_index\n",
       "column_name                               \n",
       "fBodyAcc-bandsEnergy()-1,16              3\n",
       "fBodyAcc-bandsEnergy()-1,24              3\n",
       "fBodyAcc-bandsEnergy()-1,8               3\n",
       "fBodyAcc-bandsEnergy()-17,24             3\n",
       "fBodyAcc-bandsEnergy()-17,32             3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dup_df = feature_name_df.groupby('column_name').count()\n",
    "print(feature_dup_df[feature_dup_df['column_index'] > 1].count())\n",
    "feature_dup_df[feature_dup_df['column_index'] > 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_feature_name_df(old_feature_name_df):\n",
    "    feature_dup_df = pd.DataFrame(data=old_feature_name_df.groupby('column_name').cumcount(),\n",
    "                                 columns=['dup_cnt'])\n",
    "    feature_dup_df = feature_dup_df.reset_index()\n",
    "    new_feature_name_df = pd.merge(old_feature_name_df.reset_index(), feature_dup_df, how='outer')\n",
    "    new_feature_name_df['column_name'] = new_feature_name_df[['column_name', 'dup_cnt']].apply(lambda x : \n",
    "                                            x[0]+'-'+str(x[1])if x[1] >0 else x[0] , axis=1)\n",
    "    \n",
    "    new_feature_name_df = new_feature_name_df.drop(['index'], axis=1)\n",
    "    return new_feature_name_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_human_dataset():\n",
    "    # 각 데이터 파일들은 공백으로 분리되어 있으므로 read_csv에서 공백 문자를 sep으로 할당.\n",
    "    feature_name_df = pd.read_csv('../ML/human_activity/features.txt', sep='\\s+',\n",
    "                                 header=None,names=['column_index','column_name'])\n",
    "    \n",
    "    # 중복된 피처명을 수정하는 get_new_feature_name_df()를 이용, 신규 피처명 DataFrame생성.\n",
    "    new_feature_name_df = get_new_feature_name_df(feature_name_df)\n",
    "    \n",
    "    #DataFrame에 피처명을 컬럼으로 부여하기 위해 리스트 객체로 다시 변환\n",
    "    feature_name = new_feature_name_df.iloc[:, 1].values.tolist()\n",
    "    \n",
    "    #학습 피처 데이터 셋과 테스트 피처 데이터를 DataFrame으로 로딩. 컬럼명은 feature_name으로 적용\n",
    "    X_train = pd.read_csv('../ML/human_activity/train/X_train.txt', sep='\\s+', names=feature_name)\n",
    "    X_test = pd.read_csv('../ML/human_activity/test/X_test.txt', sep='\\s+' , names=feature_name)\n",
    "    \n",
    "    # 학습 레이블과 테스트 레이블 데이터를 DataFrame으로 로딩하고 컬럼명은 action으로 부여.\n",
    "    y_train = pd.read_csv('../ML/human_activity/train/y_train.txt' , sep='\\s+', header=None, names=['action'])\n",
    "    y_test = pd.read_csv('../ML/human_activity/test/y_test.txt', sep='\\s+', header=None, names=['action'])\n",
    "    \n",
    "    # 로드된 학습/테스트용 DataFrame을 모두 반환\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_human_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hanky\\OneDrive\\바탕 화면\\유비온\\유비온_Python\\ML\\human_activity.ipynb 셀 5\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hanky/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/%EC%9C%A0%EB%B9%84%EC%98%A8/%EC%9C%A0%EB%B9%84%EC%98%A8_Python/ML/human_activity.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hanky/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/%EC%9C%A0%EB%B9%84%EC%98%A8/%EC%9C%A0%EB%B9%84%EC%98%A8_Python/ML/human_activity.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m gb_clf \u001b[39m=\u001b[39m GradientBoostingClassifier(random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/hanky/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/%EC%9C%A0%EB%B9%84%EC%98%A8/%EC%9C%A0%EB%B9%84%EC%98%A8_Python/ML/human_activity.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m gb_clf\u001b[39m.\u001b[39;49mfit(X_train,y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hanky/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/%EC%9C%A0%EB%B9%84%EC%98%A8/%EC%9C%A0%EB%B9%84%EC%98%A8_Python/ML/human_activity.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m gb_pred \u001b[39m=\u001b[39m gb_clf\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hanky/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/%EC%9C%A0%EB%B9%84%EC%98%A8/%EC%9C%A0%EB%B9%84%EC%98%A8_Python/ML/human_activity.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m gb_accuracy \u001b[39m=\u001b[39m accuracy_score(y_test, gb_pred)\n",
      "File \u001b[1;32mc:\\Users\\hanky\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:668\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    665\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resize_state()\n\u001b[0;32m    667\u001b[0m \u001b[39m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 668\u001b[0m n_stages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_stages(\n\u001b[0;32m    669\u001b[0m     X,\n\u001b[0;32m    670\u001b[0m     y,\n\u001b[0;32m    671\u001b[0m     raw_predictions,\n\u001b[0;32m    672\u001b[0m     sample_weight,\n\u001b[0;32m    673\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rng,\n\u001b[0;32m    674\u001b[0m     X_val,\n\u001b[0;32m    675\u001b[0m     y_val,\n\u001b[0;32m    676\u001b[0m     sample_weight_val,\n\u001b[0;32m    677\u001b[0m     begin_at_stage,\n\u001b[0;32m    678\u001b[0m     monitor,\n\u001b[0;32m    679\u001b[0m )\n\u001b[0;32m    681\u001b[0m \u001b[39m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \u001b[39mif\u001b[39;00m n_stages \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\hanky\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:745\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    738\u001b[0m     old_oob_score \u001b[39m=\u001b[39m loss_(\n\u001b[0;32m    739\u001b[0m         y[\u001b[39m~\u001b[39msample_mask],\n\u001b[0;32m    740\u001b[0m         raw_predictions[\u001b[39m~\u001b[39msample_mask],\n\u001b[0;32m    741\u001b[0m         sample_weight[\u001b[39m~\u001b[39msample_mask],\n\u001b[0;32m    742\u001b[0m     )\n\u001b[0;32m    744\u001b[0m \u001b[39m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m raw_predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_stage(\n\u001b[0;32m    746\u001b[0m     i,\n\u001b[0;32m    747\u001b[0m     X,\n\u001b[0;32m    748\u001b[0m     y,\n\u001b[0;32m    749\u001b[0m     raw_predictions,\n\u001b[0;32m    750\u001b[0m     sample_weight,\n\u001b[0;32m    751\u001b[0m     sample_mask,\n\u001b[0;32m    752\u001b[0m     random_state,\n\u001b[0;32m    753\u001b[0m     X_csc,\n\u001b[0;32m    754\u001b[0m     X_csr,\n\u001b[0;32m    755\u001b[0m )\n\u001b[0;32m    757\u001b[0m \u001b[39m# track deviance (= loss)\u001b[39;00m\n\u001b[0;32m    758\u001b[0m \u001b[39mif\u001b[39;00m do_oob:\n",
      "File \u001b[1;32mc:\\Users\\hanky\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:247\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    244\u001b[0m     sample_weight \u001b[39m=\u001b[39m sample_weight \u001b[39m*\u001b[39m sample_mask\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat64)\n\u001b[0;32m    246\u001b[0m X \u001b[39m=\u001b[39m X_csr \u001b[39mif\u001b[39;00m X_csr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m X\n\u001b[1;32m--> 247\u001b[0m tree\u001b[39m.\u001b[39;49mfit(X, residual, sample_weight\u001b[39m=\u001b[39;49msample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    249\u001b[0m \u001b[39m# update tree leaves\u001b[39;00m\n\u001b[0;32m    250\u001b[0m loss\u001b[39m.\u001b[39mupdate_terminal_regions(\n\u001b[0;32m    251\u001b[0m     tree\u001b[39m.\u001b[39mtree_,\n\u001b[0;32m    252\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    259\u001b[0m     k\u001b[39m=\u001b[39mk,\n\u001b[0;32m    260\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\hanky\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py:1342\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1314\u001b[0m     \u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m \n\u001b[0;32m   1316\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1339\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1340\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1342\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   1343\u001b[0m         X,\n\u001b[0;32m   1344\u001b[0m         y,\n\u001b[0;32m   1345\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1346\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m   1347\u001b[0m     )\n\u001b[0;32m   1348\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\hanky\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py:458\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    448\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    449\u001b[0m         splitter,\n\u001b[0;32m    450\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    456\u001b[0m     )\n\u001b[1;32m--> 458\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[0;32m    460\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    461\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import time\n",
    "import warnings\n",
    "from sklearn.metrics import accuracy_score\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_human_dataset()\n",
    "\n",
    "# GBM 수행 시간 측정을 위함. 시작시간 설정.\n",
    "start_time = time.time()\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=0)\n",
    "gb_clf.fit(X_train,y_train)\n",
    "gb_pred = gb_clf.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "print(gb_accuracy)\n",
    "\n",
    "print('GBM 정확도: {0:4f}'.format(gb_accuracy))\n",
    "print('GBM 수행시간 : {0:1f}초'.format(time.time()-start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\hanky\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.6.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\hanky\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from xgboost) (1.23.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\hanky\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from xgboost) (1.9.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5], got [1 2 3 4 5 6]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hanky\\OneDrive\\바탕 화면\\유비온\\유비온_Python\\ML\\human_activity.ipynb 셀 8\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hanky/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/%EC%9C%A0%EB%B9%84%EC%98%A8/%EC%9C%A0%EB%B9%84%EC%98%A8_Python/ML/human_activity.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hanky/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/%EC%9C%A0%EB%B9%84%EC%98%A8/%EC%9C%A0%EB%B9%84%EC%98%A8_Python/ML/human_activity.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m xg_clf \u001b[39m=\u001b[39m XGBClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m, learning_rate\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, max_depth\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, random_state \u001b[39m=\u001b[39m \u001b[39m32\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/hanky/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/%EC%9C%A0%EB%B9%84%EC%98%A8/%EC%9C%A0%EB%B9%84%EC%98%A8_Python/ML/human_activity.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m xg_clf\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hanky/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/%EC%9C%A0%EB%B9%84%EC%98%A8/%EC%9C%A0%EB%B9%84%EC%98%A8_Python/ML/human_activity.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m xg_pred \u001b[39m=\u001b[39m xg_clf\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hanky/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/%EC%9C%A0%EB%B9%84%EC%98%A8/%EC%9C%A0%EB%B9%84%EC%98%A8_Python/ML/human_activity.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m xg_accuracy \u001b[39m=\u001b[39m accuracy_score(y_test, xg_pred)\n",
      "File \u001b[1;32mc:\\Users\\hanky\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:575\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    574\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 575\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\hanky\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py:1357\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1352\u001b[0m     expected_classes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_)\n\u001b[0;32m   1353\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1354\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m expected_classes\u001b[39m.\u001b[39mshape\n\u001b[0;32m   1355\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m==\u001b[39m expected_classes)\u001b[39m.\u001b[39mall()\n\u001b[0;32m   1356\u001b[0m ):\n\u001b[1;32m-> 1357\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1358\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1359\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected: \u001b[39m\u001b[39m{\u001b[39;00mexpected_classes\u001b[39m}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1360\u001b[0m     )\n\u001b[0;32m   1362\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1364\u001b[0m \u001b[39mif\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5], got [1 2 3 4 5 6]"
     ]
    }
   ],
   "source": [
    "# !pip install xgboost\n",
    "from xgboost import XGBClassifier\n",
    "import time\n",
    "import warnings\n",
    "from sklearn.metrics import accuracy_score\n",
    "warnings.filterwarnings('ignore')\n",
    "X_train, X_test, y_train, y_test = get_human_dataset()\n",
    "start_time = time.time()\n",
    "xg_clf = XGBClassifier(n_estimators=500, learning_rate=0.2, max_depth=4, random_state = 32)\n",
    "xg_clf.fit(X_train, y_train)\n",
    "xg_pred = xg_clf.predict(X_test)\n",
    "xg_accuracy = accuracy_score(y_test, xg_pred)\n",
    "print('XG 정확도: {0: .4f}'.format(xg_accuracy))\n",
    "print('XG 수행 시간: {0: .1f} 초 '.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47588a3850b92a15dad958dac736ad5c8ea0d8bbad34b05dc7eef037fef8180a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
